# Llama3WebApp
Project to Automatically Download, Install, and Run Docker, Ollama, Llama3, Open-WebUI or Llama3 Web App on Your Local Browser

SetupLlama3WebApp is for Windows 10 only.

After you git cloned or downloaded and unzipped SetupLlama3WebApp.zip file, do the following to run LLAMA3 Web App in local browser.

1) Right-click the SetupLlama3WebApp.bat file and click Run as administrator.
2) At this point, the SetupLlama3WebApp.bat starts to      
   automatically download, install, and run Docker Desktop, Ollama, Llama3, and Open-WebUI and launch Open-WebUI or Llama3 Web App for you 
   to register off-line local user and use Llama3 in you local web browser.
3) When Docker Descktop Survey window pops up, just select your desired choices and select Next or Continue to finish setting up Docker Desktop.
4) Return to the Command Prompt window and press Enter key to continue. 
5) Wait until you see the Web browser appears, create a local user account, click on the Model dropdown list, and select Llama3:latest-8b.
   Note: Registered user information only resides on your local/private computer. It is not given to any remote server. Everything resides locally on your computer.
5) Wait for 15-20 seconds for Llama3:latest-8b to fully load. Then, type hello or hi and press Enter key to verify whether Llama3 is ready to accept and answer your questions.
   If Llama3 responses to your hello or hi, then you can continue to ask Llama3 any questions. If it does not answer you, wait for 30 seconds and try again.
   If it still does not answer you, you have to refresh the web page, and try the process again.
   Heads up: The voice recognition has not been implemented in this version yet.   
4) To quit, just close the Open-WebUI tap or page and close the Command Prompt window.
7) To run LlAMA3 Web App or Open-WebUI again, just right-click the SetupLlama3WebApp.bat file again and click Run as administrator.
   Note: This time, the SetupLlama3WebApp.bat file won't re-download and re-setup Docker Desktop, Ollama, Open-WebUI, nor LLAMA3 model. 
   It will just run Open-WebUI or Llama3 Web App for you to use.
